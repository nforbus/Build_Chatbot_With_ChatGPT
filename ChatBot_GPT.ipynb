{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZsmdM0NY92Y"
   },
   "source": [
    "#Task 1: Import Libraries and Define the OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAbalTS5Wp4X",
    "outputId": "aa03f114-33ff-4002-e714-66499c554537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.16.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\samur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# ! pip install openai\n",
    "! pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKePH20SW5aA",
    "outputId": "6af9a551-1e83-4307-8d99-72ddf33986f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.2.3\n",
      "    Uninstalling openai-1.2.3:\n",
      "      Successfully uninstalled openai-1.2.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "! pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IwaIzzF4WsDT"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# go to \"https://platform.openai.com/api-keys\" to get your api key\n",
    "\n",
    "# Define OpenAI API key\n",
    "openai.api_key = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMBxHl5afnho"
   },
   "source": [
    "#Task 2: Chat with ChatGPT using the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDBUWcq-fqPh",
    "outputId": "382cac64-f9ff-4af0-d3eb-f63481e437eb"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT: \n",
      "\n",
      "Stranger:\n",
      "\n",
      "Hello! How are you doing today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "# Function to send a message to ChatGPT and get a response\n",
    "def chat_with_gpt(message):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-3.5-turbo-instruct\",  # You can choose a different engine if needed\n",
    "        prompt=message,\n",
    "        max_tokens=10  # Adjust this based on your desired response length\n",
    "    )\n",
    "    return response.choices[0].text\n",
    "\n",
    "# Start a conversation\n",
    "conversation = []\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    conversation.append(f\"You: {user_input}\")\n",
    "\n",
    "    # Exit the loop if the user wants to end the conversation\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Generate a response from ChatGPT\n",
    "    response = chat_with_gpt(\"\\n\".join(conversation))\n",
    "    print(f\"ChatGPT: {response}\")\n",
    "    conversation.append(f\"ChatGPT: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUu9y6EzZSKl"
   },
   "source": [
    "#Task 3: Define the Chatbot Conversation Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l9wn1GojXHIt"
   },
   "outputs": [],
   "source": [
    "def chatbot_conversation(initial_prompt):\n",
    "    # Initialize conversation with initial prompt\n",
    "    prompt = initial_prompt\n",
    "\n",
    "    # Continuously interact with the user until they end the conversation\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"User: \")\n",
    "\n",
    "        # Send user input and current prompt to ChatGPT API and receive response\n",
    "        response = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\", # this model is specifically designed to understand and generate natural language text (instruction-following tasks)\n",
    "            prompt=prompt + \"\\nUser: \" + user_input,\n",
    "            temperature= 0.7, ### insert the temperature here ###\n",
    "            max_tokens= 50 ### insert the max number tokens here ###\n",
    "        )\n",
    "\n",
    "        # Extract and display ChatGPT's response\n",
    "        chatbot_response = response.choices[0].text\n",
    "        print(\"Chatbot:\", chatbot_response)\n",
    "\n",
    "        # Update prompt for next iteration\n",
    "        prompt = prompt + \"\\nChatbot: \" + chatbot_response + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhfcrzXjZXFD"
   },
   "source": [
    "#Task 4: Handle Frequently Asked Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hje9d3v9i1g8"
   },
   "source": [
    "###Handling FAQs for Product Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2y0Tvm6vXJmr"
   },
   "outputs": [],
   "source": [
    "def product_information_faq(user_input):\n",
    "    # Identify product-related keywords in user input\n",
    "    product_keywords = [\"product\", \"item\", \"details\", \"features\", \"specifications\", \"capabilities\"] ### insert product keywords here ###\n",
    "    for keyword in product_keywords:\n",
    "        if keyword in user_input.lower():\n",
    "            # Provide relevant product information based on user's query\n",
    "            print(\"Please specify the product you're interested in and I'll provide more details.\")\n",
    "            product_name = input(\"Product name: \")\n",
    "            # Use product_name to retrieve and display product information from a database or API\n",
    "            print(\"Product information for \" + product_name + \":\")\n",
    "            # Display product details, features, and specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5fWR3z9ZcEU"
   },
   "source": [
    "###Handling FAQs for Shipping and Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5t0fDzC3XMCd"
   },
   "outputs": [],
   "source": [
    "def shipping_and_returns_faq(user_input):\n",
    "    # Identify shipping or returns keywords in user input\n",
    "    shipping_keywords = [\"shipping\", \"delivery\", \"courier\", \"timeline\"] ### insert product keywords here ###\n",
    "    returns_keywords = [\"return\", \"refund\", \"exchange\", \"policy\"]\n",
    "\n",
    "    for keyword in shipping_keywords:\n",
    "        if keyword in user_input.lower():\n",
    "            # Provide relevant shipping information based on user's query\n",
    "            print(\"Shipping options and timelines for your order:\")\n",
    "            # Display shipping options, delivery timelines, and estimated delivery dates\n",
    "\n",
    "    for keyword in returns_keywords:\n",
    "        if keyword in user_input.lower():\n",
    "            # Provide relevant returns information based on user's query\n",
    "            print(\"Our returns policy and procedures:\")\n",
    "            # Display returns policy, return initiation process, and refund or exchange options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjko2N6cZh-Q"
   },
   "source": [
    "###Handling FAQs for Customer Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNxR3k_UXOSh"
   },
   "outputs": [],
   "source": [
    "def customer_support_faq(user_input):\n",
    "    # Identify customer support keywords in user input\n",
    "    support_keywords = [\"help\", \"issue\", \"problem\", \"assistance\", \"support\"] ### insert product keywords here ###\n",
    "\n",
    "    for keyword in support_keywords:\n",
    "        if keyword in user_input.lower():\n",
    "            # Provide relevant customer support assistance\n",
    "            print(\"Please describe your issue or problem in detail so we can assist you.\")\n",
    "            user_issue = input(\"Description of issue: \")\n",
    "            # Use user_issue to identify and resolve the user's problem or direct them to relevant support resources\n",
    "            print(\"We're here to help. Please provide more details about your issue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5EOYnzgZnFy"
   },
   "source": [
    "#Task 5: Initiate Chatbot Conversation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irKGuPtuXQ8R",
    "outputId": "5d726d95-81cf-491b-c09b-34d4786cc4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our customer service chatbot. How can I help you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: , how are you?\n",
      "\n",
      "AI: I'm a machine learning model designed to interact with humans, so I don't have feelings or emotions like a human does. How can I assist you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Why are there answers for both chatbot and AI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: ?\n",
      "Chatbot: Some people use the terms \"chatbot\" and \"AI\" interchangeably, but technically they are different. A chatbot is a computer program designed to simulate conversation with human users, while AI (artificial intelligence) refers to\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  So you have two personalities?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Chatbot: No, I don't have personalities like a human does. I am programmed to respond in a certain way based on the input I receive.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Neat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: , can you answer any question?\n",
      "\n",
      "Chatbot: I am trained to answer a wide variety of questions, but my knowledge is limited to what I have been programmed with. Is there something specific you would like to know?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using our chatbot. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "# Start the chatbot conversation with a welcome message\n",
    "print(\"Welcome to our customer service chatbot. How can I help you today?\")\n",
    "\n",
    "# Initialize conversation with an empty prompt\n",
    "prompt = \"\"\n",
    "\n",
    "# Continuously interact with the user and handle their queries\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # Check if user wants to end the conversation\n",
    "    if user_input.lower() == \"bye\" or user_input.lower() == \"quit\":\n",
    "        print(\"Thank you for using our chatbot. Have a great day!\")\n",
    "        break\n",
    "\n",
    "    # Construct the prompt for ChatGPT API\n",
    "    prompt += \"\\nUser: \" + user_input\n",
    "\n",
    "    # Send user input and current prompt to ChatGPT API and receive response\n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=50\n",
    "    )\n",
    "\n",
    "    # Extract and display ChatGPT's response\n",
    "    chatbot_response = response.choices[0].text\n",
    "\n",
    "    # Skip empty responses\n",
    "    if not chatbot_response:\n",
    "        continue\n",
    "\n",
    "    print(\"Chatbot:\", chatbot_response)\n",
    "\n",
    "    # Update prompt for next iteration\n",
    "    prompt += \"\\nChatbot: \" + chatbot_response + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-tSslz4b8df"
   },
   "source": [
    "#Task 6: Build a Customized Chatbot and Chat with It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhR3p6ADc_m2",
    "outputId": "ff28b441-07a5-4083-c848-0dc398df1558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our ebook customer service chatbot. How can I assist you with your ebook queries today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: System: Hi there! How can I assist you with ebooks today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What time is it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Chatbot:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What time is it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Chatbot: The current time is 3:27 PM. Is there something specific you need help with regarding ebooks?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  No\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Chatbot:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  No\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Chatbot: Is there anything else I can assist you with?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  No\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Chatbot: Chatbot: Okay, have a great day! Don't hesitate to reach out if you need help with ebooks in the future.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  ebook what is your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Chatbot: Chatbot: My name is Ebook Assistant. How may I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Your name is now Betty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Chatbot: Chatbot: Chatbot: Okay, I have updated my name to Betty. What can I assist you with, Betty?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Chatbot: Chatbot: Chatbot: My name is Betty. How may I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using our chatbot. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "# Import the OpenAI library\n",
    "import openai\n",
    "\n",
    "# Start the chatbot conversation with a welcome message\n",
    "print(\"Welcome to our ebook customer service chatbot. How can I assist you with your ebook queries today?\")\n",
    "\n",
    "# Initialize conversation with a system message to set the context for ChatGPT\n",
    "prompt = \"System: You are a customer service AI knowledgeable about ebooks.\\\\n\"\n",
    "\n",
    "# Continuously interact with the user and handle their queries\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # Check if user wants to end the conversation\n",
    "    if user_input.lower() in [\"bye\", \"quit\"]:\n",
    "        print(\"Thank you for using our chatbot. Have a great day!\")\n",
    "        break\n",
    "\n",
    "    # Add user input to prompt\n",
    "    prompt += \"User: \" + user_input + \"\\\\n\"\n",
    "\n",
    "    # Send user input and current prompt to ChatGPT API and receive response\n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=50,\n",
    "        stop=[\"\\\\n\", \" User:\", \" System:\"]\n",
    "    )\n",
    "\n",
    "    # Extract and display ChatGPT's response\n",
    "    chatbot_response = response.choices[0].text.strip()\n",
    "\n",
    "    # Skip empty responses\n",
    "    if not chatbot_response:\n",
    "        continue\n",
    "\n",
    "    # Check if the user's query is off-topic\n",
    "    if \"ebook\" not in user_input.lower() and \"book\" not in user_input.lower() and any(word in chatbot_response.lower() for word in [\"sorry\", \"don't know\", \"not sure\"]):\n",
    "        print(\"Chatbot: I'm sorry, I specialize in ebooks. Could you please ask something related to that topic?\")\n",
    "    else:\n",
    "        print(\"Chatbot:\", chatbot_response)\n",
    "\n",
    "    # Update prompt for next iteration\n",
    "    prompt += \"Chatbot: \" + chatbot_response + \"\\\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OQV8KnyggaX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
